{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import weaviate\n",
    "import uuid\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the squad v2 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 5.28k/5.28k [00:00<00:00, 1.75MB/s]\n",
      "Downloading metadata: 100%|██████████| 2.40k/2.40k [00:00<00:00, 4.12MB/s]\n",
      "Downloading readme: 100%|██████████| 8.02k/8.02k [00:00<00:00, 1.08MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset squad_v2/squad_v2 to /home/vscode/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 42.1MB [00:00, 50.1MB/s]/2 [00:00<?, ?it/s]\n",
      "Downloading data: 4.37MB [00:00, 42.8MB/s]/2 [00:02<00:02,  2.02s/it]\n",
      "Downloading data files: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 2346.46it/s]\n",
      "                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad_v2 downloaded and prepared to /home/vscode/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "num_samples = 100\n",
    "\n",
    "dataset = load_dataset(\"squad_v2\", split=\"validation\")\\\n",
    "    .shuffle(seed=42)\\\n",
    "    .select(range(num_samples))\\\n",
    "    .rename_column(\"id\", \"docid\")\n",
    "\n",
    "# to check the answer later\n",
    "df = dataset.to_pandas().set_index(\"docid\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to weaviate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.Client(\"http://localhost:8080\")\n",
    "\n",
    "doc_class_schema = {\n",
    "    \"class\": \"Document\",\n",
    "    \"description\": \"A factual document\",\n",
    "    \"properties\": [{\n",
    "        \"name\": \"context\",\n",
    "        \"dataType\": [\"text\"]},\n",
    "        {\n",
    "        \"name\": \"docid\",\n",
    "        \"dataType\": [\"string\"]\n",
    "    }\n",
    "    ],\n",
    "    \"moduleConfig\": {\n",
    "        \"qna-openai\": {\n",
    "          \"model\": \"text-davinci-002\",\n",
    "          \"maxTokens\": 16,\n",
    "          \"temperature\": 0.0,\n",
    "          \"topP\": 1,\n",
    "          \"frequencyPenalty\": 0.0,\n",
    "          \"presencePenalty\": 0.0\n",
    "        }\n",
    "      }\n",
    "}\n",
    "\n",
    "client.schema.create_class(doc_class_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.batch(batch_size=10, dynamic=True, num_workers=1)\n",
    "\n",
    "with client.batch as batch:\n",
    "    for d in dataset.remove_columns([\"title\", \"answers\", \"question\"]):\n",
    "        batch.add_data_object(\n",
    "            data_object=d,\n",
    "            class_name=\"Document\"\n",
    "        )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask a question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick questions that have answers\n",
    "true_answer = None\n",
    "\n",
    "while not true_answer:\n",
    "    sample_triple = df.sample(1)\n",
    "    question = sample_triple[\"question\"].values[0]\n",
    "    true_answer = sample_triple[\"answers\"].values[0]\n",
    "    context = sample_triple[\"context\"].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = {\n",
    "    \"question\": question,\n",
    "    \"properties\": \"context\"\n",
    "}\n",
    "\n",
    "# result = (\n",
    "#     client.query\n",
    "#     .get(\"Document\", [\"_additional {answer {hasAnswer certainty property result startPosition endPosition} }\"])\n",
    "#     .with_ask(ask)\n",
    "#     .with_limit(1)\n",
    "#     .do()\n",
    "# )\n",
    "\n",
    "result = (\n",
    "    client.query\n",
    "    .get(\"Document\", [\"_additional {answer {hasAnswer property result startPosition endPosition} }\"])\n",
    "    .with_ask(ask)\n",
    "    .with_limit(1)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "model_answer = result[\"data\"][\"Get\"][\"Document\"][0][\"_additional\"][\"answer\"][\"result\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "The Black Death is thought to have originated in the arid plains of Central Asia, where it then travelled along the Silk Road, reaching Crimea by 1343. From there, it was most likely carried by Oriental rat fleas living on the black rats that were regular passengers on merchant ships. Spreading throughout the Mediterranean and Europe, the Black Death is estimated to have killed 30–60% of Europe's total population. In total, the plague reduced the world population from an estimated 450 million down to 350–375 million in the 14th century. The world population as a whole did not recover to pre-plague levels until the 17th century. The plague recurred occasionally in Europe until the 19th century.\n",
      "--------------------------------------------------------------------------------\n",
      "Question:\n",
      "How did the black death make it to the Mediterranean and Europe?\n",
      "--------------------------------------------------------------------------------\n",
      "Model answer:\n",
      " The black death made it to the Mediterranean and Europe by being carried by Oriental rat\n",
      "--------------------------------------------------------------------------------\n",
      "True answer:\n",
      "{'text': array(['merchant ships.', 'merchant ships', 'Silk Road'], dtype=object), 'answer_start': array([270, 270, 116], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Context:\\n{context}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Question:\\n{question}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Model answer:\\n{model_answer}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"True answer:\\n{true_answer}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
